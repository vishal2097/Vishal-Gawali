{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assessment_04_ques_01 (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-1ioOlCo6xV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6Ju8uWLo8mO"
      },
      "source": [
        "**Assessment** - **4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA_3d2O4sJg5"
      },
      "source": [
        "Git Hub Link-https://github.com/vishal2097/Vishal-Gawali"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3RO6UzlpfX0"
      },
      "source": [
        "**REG** **NO**-**20MAI0049**\n",
        "\n",
        "**NAME**-**Vishal** **Manoharrao** **Gawali**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIcX0sXJro4u"
      },
      "source": [
        "Q1-Implementalex net problem in form of transfer learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZJZvOlhSEff"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxXn_SBsRv3-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ineUGnZ_SAFd"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVHMCEpqSU-D"
      },
      "source": [
        "### AlexNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7jAh9TjSDlf",
        "outputId": "ca924e23-1862-4143-99ba-a69c17c3dfba"
      },
      "source": [
        "AlexNet = Sequential()\n",
        "\n",
        "#1st Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#2nd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#3rd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#4th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#5th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#Passing it to a Fully Connected layer\n",
        "AlexNet.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#2nd Fully Connected Layer\n",
        "AlexNet.add(Dense(4096))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#3rd Fully Connected Layer\n",
        "AlexNet.add(Dense(1000))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#Output Layer\n",
        "AlexNet.add(Dense(10))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('softmax'))\n",
        "\n",
        "#Model Summary\n",
        "AlexNet.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 8, 8, 96)          34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 8, 8, 96)          384       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 8, 8, 96)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 4, 4, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                10010     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,730,506\n",
            "Trainable params: 25,709,350\n",
            "Non-trainable params: 21,156\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EssX_oC6Sb-o"
      },
      "source": [
        "AlexNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAyVww78S_-z"
      },
      "source": [
        "### Importing CIFAR dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45Q8ccuwS66b",
        "outputId": "f9f27f5a-d046-4573-abcb-039eae120453"
      },
      "source": [
        "\n",
        "#Keras library for CIFAR dataset\n",
        "from keras.datasets import cifar10\n",
        "(x_train, y_train),(x_test, y_test)=cifar10.load_data()\n",
        "\n",
        "#Train-validation-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\n",
        "\n",
        "\n",
        "#Dimension of the CIFAR10 dataset\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "((35000, 32, 32, 3), (35000, 1))\n",
            "((15000, 32, 32, 3), (15000, 1))\n",
            "((10000, 32, 32, 3), (10000, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61ySv80GTEWz",
        "outputId": "f6554511-86b8-4e4d-c56d-c2563ca368c3"
      },
      "source": [
        "#Onehot Encoding the labels.\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)\n",
        "\n",
        "#Verifying the dimension after one hot encoding\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((35000, 32, 32, 3), (35000, 10))\n",
            "((15000, 32, 32, 3), (15000, 10))\n",
            "((10000, 32, 32, 3), (10000, 10))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKEZp5ZaTOyt",
        "outputId": "852b865d-321b-4a3c-d95e-8bb8dff0d357"
      },
      "source": [
        "#Defining the parameters\n",
        "batch_size= 100\n",
        "epochs=50\n",
        "#Training the model\n",
        "AlexNet.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "350/350 [==============================] - 42s 23ms/step - loss: 1.8025 - accuracy: 0.3502 - val_loss: 2.1155 - val_accuracy: 0.2917\n",
            "Epoch 2/50\n",
            "350/350 [==============================] - 8s 22ms/step - loss: 1.3827 - accuracy: 0.5137 - val_loss: 2.2131 - val_accuracy: 0.2712\n",
            "Epoch 3/50\n",
            "350/350 [==============================] - 8s 22ms/step - loss: 1.2374 - accuracy: 0.5736 - val_loss: 2.5488 - val_accuracy: 0.2906\n",
            "Epoch 4/50\n",
            "350/350 [==============================] - 8s 22ms/step - loss: 1.1248 - accuracy: 0.6135 - val_loss: 2.3507 - val_accuracy: 0.3020\n",
            "Epoch 5/50\n",
            "350/350 [==============================] - 8s 22ms/step - loss: 1.0081 - accuracy: 0.6575 - val_loss: 1.5013 - val_accuracy: 0.4889\n",
            "Epoch 6/50\n",
            "350/350 [==============================] - 8s 22ms/step - loss: 0.9166 - accuracy: 0.6925 - val_loss: 1.8674 - val_accuracy: 0.4064\n",
            "Epoch 7/50\n",
            "350/350 [==============================] - 8s 22ms/step - loss: 0.8264 - accuracy: 0.7272 - val_loss: 1.6402 - val_accuracy: 0.4764\n",
            "Epoch 8/50\n",
            "350/350 [==============================] - 8s 22ms/step - loss: 0.7453 - accuracy: 0.7543 - val_loss: 1.6365 - val_accuracy: 0.4875\n",
            "Epoch 9/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.6548 - accuracy: 0.7860 - val_loss: 1.4691 - val_accuracy: 0.5314\n",
            "Epoch 10/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.5750 - accuracy: 0.8167 - val_loss: 1.3861 - val_accuracy: 0.5489\n",
            "Epoch 11/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.5060 - accuracy: 0.8397 - val_loss: 1.7441 - val_accuracy: 0.4981\n",
            "Epoch 12/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.4336 - accuracy: 0.8656 - val_loss: 1.5929 - val_accuracy: 0.5087\n",
            "Epoch 13/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.3617 - accuracy: 0.8886 - val_loss: 1.8736 - val_accuracy: 0.4693\n",
            "Epoch 14/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.3239 - accuracy: 0.9014 - val_loss: 1.5781 - val_accuracy: 0.5617\n",
            "Epoch 15/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.2777 - accuracy: 0.9151 - val_loss: 1.7415 - val_accuracy: 0.5118\n",
            "Epoch 16/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.2378 - accuracy: 0.9279 - val_loss: 1.4135 - val_accuracy: 0.5937\n",
            "Epoch 17/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.2214 - accuracy: 0.9344 - val_loss: 1.8686 - val_accuracy: 0.5181\n",
            "Epoch 18/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.2017 - accuracy: 0.9376 - val_loss: 2.5470 - val_accuracy: 0.3935\n",
            "Epoch 19/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1806 - accuracy: 0.9461 - val_loss: 1.9747 - val_accuracy: 0.5072\n",
            "Epoch 20/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1654 - accuracy: 0.9478 - val_loss: 1.4678 - val_accuracy: 0.6041\n",
            "Epoch 21/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1516 - accuracy: 0.9538 - val_loss: 1.8827 - val_accuracy: 0.5101\n",
            "Epoch 22/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1326 - accuracy: 0.9597 - val_loss: 1.8885 - val_accuracy: 0.5062\n",
            "Epoch 23/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1238 - accuracy: 0.9633 - val_loss: 1.8845 - val_accuracy: 0.5280\n",
            "Epoch 24/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1414 - accuracy: 0.9565 - val_loss: 1.9168 - val_accuracy: 0.5187\n",
            "Epoch 25/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1221 - accuracy: 0.9637 - val_loss: 1.8636 - val_accuracy: 0.5290\n",
            "Epoch 26/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1063 - accuracy: 0.9669 - val_loss: 1.7700 - val_accuracy: 0.5314\n",
            "Epoch 27/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1046 - accuracy: 0.9690 - val_loss: 1.7856 - val_accuracy: 0.5534\n",
            "Epoch 28/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0983 - accuracy: 0.9703 - val_loss: 1.9766 - val_accuracy: 0.5251\n",
            "Epoch 29/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0969 - accuracy: 0.9687 - val_loss: 3.0384 - val_accuracy: 0.3981\n",
            "Epoch 30/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0986 - accuracy: 0.9686 - val_loss: 2.5868 - val_accuracy: 0.4213\n",
            "Epoch 31/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0898 - accuracy: 0.9725 - val_loss: 2.1307 - val_accuracy: 0.5178\n",
            "Epoch 32/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0825 - accuracy: 0.9736 - val_loss: 1.8879 - val_accuracy: 0.5379\n",
            "Epoch 33/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0804 - accuracy: 0.9759 - val_loss: 1.8544 - val_accuracy: 0.5537\n",
            "Epoch 34/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0753 - accuracy: 0.9762 - val_loss: 2.1241 - val_accuracy: 0.5105\n",
            "Epoch 35/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0806 - accuracy: 0.9752 - val_loss: 2.2779 - val_accuracy: 0.4895\n",
            "Epoch 36/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0659 - accuracy: 0.9800 - val_loss: 1.7411 - val_accuracy: 0.5755\n",
            "Epoch 37/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0701 - accuracy: 0.9781 - val_loss: 2.0713 - val_accuracy: 0.5187\n",
            "Epoch 38/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0736 - accuracy: 0.9774 - val_loss: 2.1112 - val_accuracy: 0.5374\n",
            "Epoch 39/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0659 - accuracy: 0.9798 - val_loss: 1.9846 - val_accuracy: 0.5577\n",
            "Epoch 40/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0668 - accuracy: 0.9792 - val_loss: 2.1696 - val_accuracy: 0.5164\n",
            "Epoch 41/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0598 - accuracy: 0.9812 - val_loss: 2.4059 - val_accuracy: 0.5084\n",
            "Epoch 42/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0584 - accuracy: 0.9814 - val_loss: 2.3301 - val_accuracy: 0.5380\n",
            "Epoch 43/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0614 - accuracy: 0.9814 - val_loss: 1.8699 - val_accuracy: 0.5836\n",
            "Epoch 44/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0574 - accuracy: 0.9820 - val_loss: 2.4067 - val_accuracy: 0.4888\n",
            "Epoch 45/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0535 - accuracy: 0.9843 - val_loss: 2.0244 - val_accuracy: 0.5480\n",
            "Epoch 46/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0521 - accuracy: 0.9843 - val_loss: 2.1841 - val_accuracy: 0.5221\n",
            "Epoch 47/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0487 - accuracy: 0.9837 - val_loss: 1.9191 - val_accuracy: 0.5819\n",
            "Epoch 48/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0538 - accuracy: 0.9829 - val_loss: 2.5480 - val_accuracy: 0.5050\n",
            "Epoch 49/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0401 - accuracy: 0.9882 - val_loss: 2.4582 - val_accuracy: 0.5007\n",
            "Epoch 50/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0526 - accuracy: 0.9828 - val_loss: 1.8415 - val_accuracy: 0.5933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe5eb64dfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-__awIVTUV-",
        "outputId": "22b98193-a89b-4ee8-a2d8-6a79ddfd2f01"
      },
      "source": [
        "AlexNet.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 1.8475 - accuracy: 0.5910\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8474574089050293, 0.5910000205039978]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ-yPj24Vj-h"
      },
      "source": [
        "!mkdir -p saved_model\n",
        "AlexNet.save('saved_model/AlexNetModel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9XLj9f2Vsko"
      },
      "source": [
        "### Transfer Learning using the AlexNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16xZ_xRMVn_O"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhD5hqW1VykJ"
      },
      "source": [
        "Base_model = tf.keras.models.load_model('saved_model/AlexNetModel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOF0PxWGV1N6"
      },
      "source": [
        "nb_train_samples =60000\n",
        "nb_valid_samples =10000\n",
        "num_classes = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUhZLU6dWMsz",
        "outputId": "ae040a35-cd2f-413a-df92-6cfe1db74fe3"
      },
      "source": [
        "\n",
        "(X_train,Y_train), (X_valid, Y_valid) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# expand new axis, channel axis \n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "\n",
        "# [optional]: we may need 3 channel (instead of 1)\n",
        "X_train = np.repeat(X_train, 3, axis=-1)\n",
        "\n",
        "# it's always better to normalize \n",
        "X_train = X_train.astype('float32') / 255\n",
        "\n",
        "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
        "X_train = tf.image.resize(X_train, [32,32]) # if we want to resize \n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "X_valid = np.expand_dims(X_valid, axis=-1)\n",
        "\n",
        "# [optional]: we may need 3 channel (instead of 1)\n",
        "X_valid = np.repeat(X_valid, 3, axis=-1)\n",
        "\n",
        "# it's always better to normalize \n",
        "X_valid = X_valid.astype('float32') / 255\n",
        "\n",
        "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
        "X_valid = tf.image.resize(X_valid, [32,32]) # if we want to resize \n",
        "\n",
        "print(X_valid.shape)\n",
        "\n",
        "from keras.utils import np_utils\n",
        "Y_train = np_utils.to_categorical(Y_train[:nb_train_samples], num_classes)\n",
        "Y_valid = np_utils.to_categorical(Y_valid[:nb_valid_samples], num_classes)\n",
        "\n",
        "print((X_train.shape,Y_train.shape))\n",
        "print((X_valid.shape,Y_valid.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(TensorShape([60000, 32, 32, 3]), (60000, 10))\n",
            "(TensorShape([10000, 32, 32, 3]), (10000, 10))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcoPRLbKWQEH"
      },
      "source": [
        "\n",
        "from keras.models import load_model\n",
        "new_model = load_model('saved_model/AlexNetModel.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP7Ch3bHWVHG",
        "outputId": "0dec0450-41ce-4776-e52f-8a0db7e5947e"
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 8, 8, 96)          34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 8, 8, 96)          384       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 8, 8, 96)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 4, 4, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                10010     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,730,506\n",
            "Trainable params: 25,709,350\n",
            "Non-trainable params: 21,156\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP6K5zQfWXQP",
        "outputId": "b987cdcb-b5b5-45d7-ab42-5e2c5543f798"
      },
      "source": [
        "new_model.trainable=False\n",
        "model = tf.keras.Sequential([\n",
        "    new_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential (Sequential)      (None, 10)                25730506  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 25,730,616\n",
            "Trainable params: 110\n",
            "Non-trainable params: 25,730,506\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bwQqEG4Wbyz",
        "outputId": "5dd5b320-0fcc-4ea5-cb21-e0e8b067aa8a"
      },
      "source": [
        "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=50, verbose=1,validation_data=(X_valid, Y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "600/600 [==============================] - 6s 9ms/step - loss: 2.3076 - accuracy: 0.1043 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
            "Epoch 2/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3024 - accuracy: 0.1082 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
            "Epoch 3/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3022 - accuracy: 0.1101 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 4/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3019 - accuracy: 0.1132 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 5/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3021 - accuracy: 0.1117 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 6/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3012 - accuracy: 0.1132 - val_loss: 2.3009 - val_accuracy: 0.1135\n",
            "Epoch 7/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3015 - accuracy: 0.1105 - val_loss: 2.3008 - val_accuracy: 0.1135\n",
            "Epoch 8/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3005 - accuracy: 0.1160 - val_loss: 2.3008 - val_accuracy: 0.1135\n",
            "Epoch 9/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3011 - accuracy: 0.1138 - val_loss: 2.3008 - val_accuracy: 0.1135\n",
            "Epoch 10/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3013 - accuracy: 0.1135 - val_loss: 2.3008 - val_accuracy: 0.1135\n",
            "Epoch 11/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3014 - accuracy: 0.1122 - val_loss: 2.3006 - val_accuracy: 0.1135\n",
            "Epoch 12/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3010 - accuracy: 0.1129 - val_loss: 2.3006 - val_accuracy: 0.1135\n",
            "Epoch 13/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3006 - val_accuracy: 0.1135\n",
            "Epoch 14/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3009 - accuracy: 0.1124 - val_loss: 2.3006 - val_accuracy: 0.1135\n",
            "Epoch 15/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3013 - accuracy: 0.1105 - val_loss: 2.3005 - val_accuracy: 0.1135\n",
            "Epoch 16/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3008 - accuracy: 0.1152 - val_loss: 2.3005 - val_accuracy: 0.1135\n",
            "Epoch 17/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3011 - accuracy: 0.1130 - val_loss: 2.3006 - val_accuracy: 0.1135\n",
            "Epoch 18/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3006 - accuracy: 0.1153 - val_loss: 2.3005 - val_accuracy: 0.1135\n",
            "Epoch 19/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3010 - accuracy: 0.1135 - val_loss: 2.3004 - val_accuracy: 0.1135\n",
            "Epoch 20/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3003 - accuracy: 0.1179 - val_loss: 2.3006 - val_accuracy: 0.1135\n",
            "Epoch 21/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3005 - val_accuracy: 0.1135\n",
            "Epoch 22/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3008 - accuracy: 0.1130 - val_loss: 2.3005 - val_accuracy: 0.1135\n",
            "Epoch 23/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3012 - accuracy: 0.1105 - val_loss: 2.3005 - val_accuracy: 0.1135\n",
            "Epoch 24/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3009 - accuracy: 0.1144 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 25/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 26/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3010 - accuracy: 0.1124 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 27/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3008 - accuracy: 0.1140 - val_loss: 2.3005 - val_accuracy: 0.1135\n",
            "Epoch 28/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3012 - accuracy: 0.1133 - val_loss: 2.3005 - val_accuracy: 0.1135\n",
            "Epoch 29/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3007 - accuracy: 0.1142 - val_loss: 2.3004 - val_accuracy: 0.1135\n",
            "Epoch 30/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3011 - accuracy: 0.1129 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 31/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3006 - accuracy: 0.1146 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 32/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3010 - accuracy: 0.1125 - val_loss: 2.3004 - val_accuracy: 0.1135\n",
            "Epoch 33/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3009 - accuracy: 0.1133 - val_loss: 2.3005 - val_accuracy: 0.1135\n",
            "Epoch 34/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3007 - accuracy: 0.1122 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 35/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3005 - accuracy: 0.1140 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 36/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3007 - accuracy: 0.1131 - val_loss: 2.3002 - val_accuracy: 0.1135\n",
            "Epoch 37/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1114 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 38/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3005 - accuracy: 0.1140 - val_loss: 2.3004 - val_accuracy: 0.1135\n",
            "Epoch 39/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3009 - accuracy: 0.1133 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 40/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3013 - accuracy: 0.1105 - val_loss: 2.3002 - val_accuracy: 0.1135\n",
            "Epoch 41/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3009 - accuracy: 0.1118 - val_loss: 2.3002 - val_accuracy: 0.1135\n",
            "Epoch 42/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3004 - accuracy: 0.1142 - val_loss: 2.3004 - val_accuracy: 0.1135\n",
            "Epoch 43/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3004 - accuracy: 0.1159 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 44/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3008 - accuracy: 0.1159 - val_loss: 2.3004 - val_accuracy: 0.1135\n",
            "Epoch 45/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3011 - accuracy: 0.1151 - val_loss: 2.3002 - val_accuracy: 0.1135\n",
            "Epoch 46/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3009 - accuracy: 0.1131 - val_loss: 2.3002 - val_accuracy: 0.1135\n",
            "Epoch 47/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3013 - accuracy: 0.1115 - val_loss: 2.3002 - val_accuracy: 0.1135\n",
            "Epoch 48/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 2.3008 - accuracy: 0.1139 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 49/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3009 - accuracy: 0.1124 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 50/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3004 - accuracy: 0.1159 - val_loss: 2.3001 - val_accuracy: 0.1135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziW4jERYWlxU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}