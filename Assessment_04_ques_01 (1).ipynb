{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assessment_04_ques_01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZJZvOlhSEff"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxXn_SBsRv3-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ineUGnZ_SAFd"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVHMCEpqSU-D"
      },
      "source": [
        "### AlexNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7jAh9TjSDlf",
        "outputId": "398ce282-9fb3-41ba-fbd7-06425d9595d1"
      },
      "source": [
        "AlexNet = Sequential()\n",
        "\n",
        "#1st Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#2nd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#3rd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#4th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#5th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#Passing it to a Fully Connected layer\n",
        "AlexNet.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#2nd Fully Connected Layer\n",
        "AlexNet.add(Dense(4096))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#3rd Fully Connected Layer\n",
        "AlexNet.add(Dense(1000))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#Output Layer\n",
        "AlexNet.add(Dense(10))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('softmax'))\n",
        "\n",
        "#Model Summary\n",
        "AlexNet.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 96)          34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 8, 8, 96)          384       \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 8, 8, 96)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 4, 4, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                10010     \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,730,506\n",
            "Trainable params: 25,709,350\n",
            "Non-trainable params: 21,156\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EssX_oC6Sb-o"
      },
      "source": [
        "AlexNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAyVww78S_-z"
      },
      "source": [
        "### Importing CIFAR dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45Q8ccuwS66b",
        "outputId": "206d65e2-e9db-435a-aaa5-953e3bdf9c50"
      },
      "source": [
        "\n",
        "#Keras library for CIFAR dataset\n",
        "from keras.datasets import cifar10\n",
        "(x_train, y_train),(x_test, y_test)=cifar10.load_data()\n",
        "\n",
        "#Train-validation-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\n",
        "\n",
        "\n",
        "#Dimension of the CIFAR10 dataset\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((35000, 32, 32, 3), (35000, 1))\n",
            "((15000, 32, 32, 3), (15000, 1))\n",
            "((10000, 32, 32, 3), (10000, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61ySv80GTEWz",
        "outputId": "efc8d829-c986-4cda-eabf-3bbd43374e79"
      },
      "source": [
        "#Onehot Encoding the labels.\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)\n",
        "\n",
        "#Verifying the dimension after one hot encoding\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((35000, 32, 32, 3), (35000, 10))\n",
            "((15000, 32, 32, 3), (15000, 10))\n",
            "((10000, 32, 32, 3), (10000, 10))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKEZp5ZaTOyt",
        "outputId": "01d26d71-d634-4245-e58f-b871d99a7502"
      },
      "source": [
        "#Defining the parameters\n",
        "batch_size= 100\n",
        "epochs=50\n",
        "#Training the model\n",
        "AlexNet.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_val, y_val))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "350/350 [==============================] - 42s 25ms/step - loss: 1.8098 - accuracy: 0.3429 - val_loss: 1.9065 - val_accuracy: 0.3217\n",
            "Epoch 2/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 1.3945 - accuracy: 0.5126 - val_loss: 2.0606 - val_accuracy: 0.3317\n",
            "Epoch 3/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 1.2528 - accuracy: 0.5637 - val_loss: 1.7813 - val_accuracy: 0.4012\n",
            "Epoch 4/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 1.1426 - accuracy: 0.6073 - val_loss: 1.3962 - val_accuracy: 0.5082\n",
            "Epoch 5/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 1.0418 - accuracy: 0.6439 - val_loss: 1.5377 - val_accuracy: 0.4795\n",
            "Epoch 6/50\n",
            "350/350 [==============================] - 8s 24ms/step - loss: 0.9356 - accuracy: 0.6840 - val_loss: 1.7639 - val_accuracy: 0.4294\n",
            "Epoch 7/50\n",
            "350/350 [==============================] - 8s 24ms/step - loss: 0.8395 - accuracy: 0.7182 - val_loss: 1.3461 - val_accuracy: 0.5429\n",
            "Epoch 8/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.7621 - accuracy: 0.7481 - val_loss: 1.7564 - val_accuracy: 0.4817\n",
            "Epoch 9/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.6710 - accuracy: 0.7795 - val_loss: 1.2950 - val_accuracy: 0.5759\n",
            "Epoch 10/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.5820 - accuracy: 0.8099 - val_loss: 1.4813 - val_accuracy: 0.5364\n",
            "Epoch 11/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.5241 - accuracy: 0.8312 - val_loss: 1.7494 - val_accuracy: 0.5055\n",
            "Epoch 12/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.4494 - accuracy: 0.8566 - val_loss: 1.5408 - val_accuracy: 0.5314\n",
            "Epoch 13/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.3804 - accuracy: 0.8816 - val_loss: 1.9876 - val_accuracy: 0.4704\n",
            "Epoch 14/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.3257 - accuracy: 0.8991 - val_loss: 1.4152 - val_accuracy: 0.5897\n",
            "Epoch 15/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.2968 - accuracy: 0.9089 - val_loss: 1.6496 - val_accuracy: 0.5273\n",
            "Epoch 16/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.2599 - accuracy: 0.9206 - val_loss: 2.3599 - val_accuracy: 0.4105\n",
            "Epoch 17/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.2215 - accuracy: 0.9354 - val_loss: 1.8928 - val_accuracy: 0.5149\n",
            "Epoch 18/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.2118 - accuracy: 0.9356 - val_loss: 1.4958 - val_accuracy: 0.5826\n",
            "Epoch 19/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1870 - accuracy: 0.9438 - val_loss: 2.2431 - val_accuracy: 0.4388\n",
            "Epoch 20/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1771 - accuracy: 0.9477 - val_loss: 1.9425 - val_accuracy: 0.5139\n",
            "Epoch 21/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1620 - accuracy: 0.9511 - val_loss: 1.6058 - val_accuracy: 0.5747\n",
            "Epoch 22/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1555 - accuracy: 0.9514 - val_loss: 2.1073 - val_accuracy: 0.5051\n",
            "Epoch 23/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1382 - accuracy: 0.9578 - val_loss: 2.5203 - val_accuracy: 0.4269\n",
            "Epoch 24/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1288 - accuracy: 0.9612 - val_loss: 2.0109 - val_accuracy: 0.5249\n",
            "Epoch 25/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1249 - accuracy: 0.9614 - val_loss: 1.6134 - val_accuracy: 0.5723\n",
            "Epoch 26/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1155 - accuracy: 0.9658 - val_loss: 1.9368 - val_accuracy: 0.5094\n",
            "Epoch 27/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1125 - accuracy: 0.9661 - val_loss: 1.7659 - val_accuracy: 0.5745\n",
            "Epoch 28/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1098 - accuracy: 0.9666 - val_loss: 1.9344 - val_accuracy: 0.5433\n",
            "Epoch 29/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0951 - accuracy: 0.9719 - val_loss: 2.0407 - val_accuracy: 0.5168\n",
            "Epoch 30/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.1021 - accuracy: 0.9669 - val_loss: 1.8398 - val_accuracy: 0.5683\n",
            "Epoch 31/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0818 - accuracy: 0.9750 - val_loss: 1.7658 - val_accuracy: 0.5601\n",
            "Epoch 32/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0872 - accuracy: 0.9738 - val_loss: 2.0798 - val_accuracy: 0.5240\n",
            "Epoch 33/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0820 - accuracy: 0.9751 - val_loss: 1.6523 - val_accuracy: 0.5838\n",
            "Epoch 34/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0760 - accuracy: 0.9776 - val_loss: 2.5765 - val_accuracy: 0.4597\n",
            "Epoch 35/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0837 - accuracy: 0.9734 - val_loss: 2.4391 - val_accuracy: 0.4719\n",
            "Epoch 36/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0757 - accuracy: 0.9772 - val_loss: 1.6775 - val_accuracy: 0.6065\n",
            "Epoch 37/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0741 - accuracy: 0.9771 - val_loss: 1.9583 - val_accuracy: 0.5094\n",
            "Epoch 38/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0699 - accuracy: 0.9791 - val_loss: 2.5864 - val_accuracy: 0.4732\n",
            "Epoch 39/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0560 - accuracy: 0.9829 - val_loss: 1.9330 - val_accuracy: 0.5823\n",
            "Epoch 40/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0656 - accuracy: 0.9800 - val_loss: 1.9834 - val_accuracy: 0.5687\n",
            "Epoch 41/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0600 - accuracy: 0.9817 - val_loss: 2.2536 - val_accuracy: 0.5227\n",
            "Epoch 42/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0612 - accuracy: 0.9813 - val_loss: 2.2386 - val_accuracy: 0.5151\n",
            "Epoch 43/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0637 - accuracy: 0.9802 - val_loss: 2.2490 - val_accuracy: 0.5103\n",
            "Epoch 44/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0600 - accuracy: 0.9813 - val_loss: 1.9614 - val_accuracy: 0.5543\n",
            "Epoch 45/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0582 - accuracy: 0.9826 - val_loss: 2.3888 - val_accuracy: 0.5050\n",
            "Epoch 46/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0565 - accuracy: 0.9828 - val_loss: 1.8048 - val_accuracy: 0.5790\n",
            "Epoch 47/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0555 - accuracy: 0.9830 - val_loss: 1.8415 - val_accuracy: 0.5940\n",
            "Epoch 48/50\n",
            "350/350 [==============================] - 8s 24ms/step - loss: 0.0627 - accuracy: 0.9812 - val_loss: 2.6933 - val_accuracy: 0.4904\n",
            "Epoch 49/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0498 - accuracy: 0.9846 - val_loss: 2.6849 - val_accuracy: 0.4728\n",
            "Epoch 50/50\n",
            "350/350 [==============================] - 8s 23ms/step - loss: 0.0517 - accuracy: 0.9845 - val_loss: 1.9986 - val_accuracy: 0.5475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9990bb9690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-__awIVTUV-",
        "outputId": "e2eb5bac-12be-459e-fb4e-9acdddca35f4"
      },
      "source": [
        "AlexNet.evaluate(x_test,y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 2.0072 - accuracy: 0.5402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.0071685314178467, 0.5401999950408936]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ-yPj24Vj-h"
      },
      "source": [
        "!mkdir -p saved_model\n",
        "AlexNet.save('saved_model/AlexNetModel.h5')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9XLj9f2Vsko"
      },
      "source": [
        "### Transfer Learning using the AlexNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16xZ_xRMVn_O"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhD5hqW1VykJ"
      },
      "source": [
        "Base_model = tf.keras.models.load_model('saved_model/AlexNetModel.h5')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOF0PxWGV1N6"
      },
      "source": [
        "nb_train_samples =60000\n",
        "nb_valid_samples =10000\n",
        "num_classes = 10"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUhZLU6dWMsz",
        "outputId": "7273cc2b-0c10-451d-9d6d-89396e70f7aa"
      },
      "source": [
        "\n",
        "(X_train,Y_train), (X_valid, Y_valid) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# expand new axis, channel axis \n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "\n",
        "# [optional]: we may need 3 channel (instead of 1)\n",
        "X_train = np.repeat(X_train, 3, axis=-1)\n",
        "\n",
        "# it's always better to normalize \n",
        "X_train = X_train.astype('float32') / 255\n",
        "\n",
        "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
        "X_train = tf.image.resize(X_train, [32,32]) # if we want to resize \n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "X_valid = np.expand_dims(X_valid, axis=-1)\n",
        "\n",
        "# [optional]: we may need 3 channel (instead of 1)\n",
        "X_valid = np.repeat(X_valid, 3, axis=-1)\n",
        "\n",
        "# it's always better to normalize \n",
        "X_valid = X_valid.astype('float32') / 255\n",
        "\n",
        "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
        "X_valid = tf.image.resize(X_valid, [32,32]) # if we want to resize \n",
        "\n",
        "print(X_valid.shape)\n",
        "\n",
        "from keras.utils import np_utils\n",
        "Y_train = np_utils.to_categorical(Y_train[:nb_train_samples], num_classes)\n",
        "Y_valid = np_utils.to_categorical(Y_valid[:nb_valid_samples], num_classes)\n",
        "\n",
        "print((X_train.shape,Y_train.shape))\n",
        "print((X_valid.shape,Y_valid.shape))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(TensorShape([60000, 32, 32, 3]), (60000, 10))\n",
            "(TensorShape([10000, 32, 32, 3]), (10000, 10))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcoPRLbKWQEH"
      },
      "source": [
        "\n",
        "from keras.models import load_model\n",
        "new_model = load_model('saved_model/AlexNetModel.h5')\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP7Ch3bHWVHG",
        "outputId": "86e9a1c0-5704-458e-b8ff-808fc5d5687b"
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 96)          34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 8, 8, 96)          384       \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 8, 8, 96)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 4, 4, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                10010     \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,730,506\n",
            "Trainable params: 25,709,350\n",
            "Non-trainable params: 21,156\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP6K5zQfWXQP",
        "outputId": "4ca15eaf-61de-4154-a956-ce62450e9c9c"
      },
      "source": [
        "new_model.trainable=False\n",
        "model = tf.keras.Sequential([\n",
        "    new_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_2 (Sequential)    (None, 10)                25730506  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 25,730,616\n",
            "Trainable params: 110\n",
            "Non-trainable params: 25,730,506\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bwQqEG4Wbyz",
        "outputId": "67bea41b-fdcf-4241-adbd-08f8156d9e61"
      },
      "source": [
        "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=50, verbose=1,validation_data=(X_valid, Y_valid))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "600/600 [==============================] - 6s 9ms/step - loss: 2.3232 - accuracy: 0.1012 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
            "Epoch 2/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1123 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
            "Epoch 3/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 4/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1120 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 5/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1110 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 6/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3009 - accuracy: 0.1146 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 7/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3015 - accuracy: 0.1115 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 8/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3016 - accuracy: 0.1123 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 9/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3016 - accuracy: 0.1099 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 10/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3017 - accuracy: 0.1107 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 11/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1112 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
            "Epoch 12/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3012 - accuracy: 0.1126 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 13/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3015 - accuracy: 0.1116 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 14/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3015 - accuracy: 0.1116 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 15/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3013 - accuracy: 0.1130 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 16/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1120 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 17/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3015 - accuracy: 0.1115 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
            "Epoch 18/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3016 - accuracy: 0.1104 - val_loss: 2.3009 - val_accuracy: 0.1135\n",
            "Epoch 19/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1117 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 20/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3019 - accuracy: 0.1099 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
            "Epoch 21/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3017 - accuracy: 0.1105 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 22/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
            "Epoch 23/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1111 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 24/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1111 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
            "Epoch 25/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3011 - accuracy: 0.1122 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 26/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3016 - accuracy: 0.1107 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 27/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3012 - accuracy: 0.1115 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 28/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3010 - accuracy: 0.1132 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 29/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3011 - accuracy: 0.1139 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 30/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3011 - accuracy: 0.1134 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 31/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3015 - accuracy: 0.1122 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 32/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1119 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 33/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3015 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 34/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3009 - val_accuracy: 0.1135\n",
            "Epoch 35/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1104 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 36/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3016 - accuracy: 0.1107 - val_loss: 2.3009 - val_accuracy: 0.1135\n",
            "Epoch 37/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1115 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 38/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3010 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 39/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3012 - accuracy: 0.1132 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 40/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1108 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 41/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 42/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3012 - accuracy: 0.1126 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
            "Epoch 43/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3011 - accuracy: 0.1132 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 44/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3011 - accuracy: 0.1116 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 45/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3016 - accuracy: 0.1116 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 46/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3009 - accuracy: 0.1130 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 47/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3015 - accuracy: 0.1129 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 48/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1114 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 49/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3015 - accuracy: 0.1112 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 50/50\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 2.3011 - accuracy: 0.1130 - val_loss: 2.3012 - val_accuracy: 0.1135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziW4jERYWlxU"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}