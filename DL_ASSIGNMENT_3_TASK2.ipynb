{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASSIGNMENT 3-TASK2.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxB3gV_IzAaY"
      },
      "source": [
        "Name- Vishal Manoharrao Gawali\n",
        "\n",
        "Reg No- 20MAI0049\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRyvYcGi02-Q"
      },
      "source": [
        "#### *ASSIGNMENT 3 TASK 2*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1pY6ZqJmKJS"
      },
      "source": [
        "from requests import get\n",
        "\n",
        "def download_file(url, file_name):\n",
        "    with open(file_name, \"wb\") as file:\n",
        "        response = get(url)\n",
        "        file.write(response.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bk0j_nOjuzy"
      },
      "source": [
        "download_file('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', 'train-images-idx3-ubyte.gz')\n",
        "download_file('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLW9SwNFpGOa"
      },
      "source": [
        "download_file('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', 't10k-images-idx3-ubyte1.gz')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwNKaCbbpnRZ"
      },
      "source": [
        "download_file('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', 't10k-labels-idx1-ubyte1.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jnQ_G7Gj2DO"
      },
      "source": [
        "# Update libraries\n",
        "!pip install seaborn==0.9.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR3Ato3Ej6OY"
      },
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.layers as layers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUMA0gxKj-yj"
      },
      "source": [
        "def read_mnist(images_path: str, labels_path: str):\n",
        "    with gzip.open(labels_path, 'rb') as labelsFile:\n",
        "        labels = np.frombuffer(labelsFile.read(), dtype=np.uint8, offset=8)\n",
        "\n",
        "    with gzip.open(images_path,'rb') as imagesFile:\n",
        "        length = len(labels)\n",
        "        # Load flat 28x28 px images (784 px), and convert them to 28x28 px\n",
        "        features = np.frombuffer(imagesFile.read(), dtype=np.uint8, offset=16) \\\n",
        "                        .reshape(length, 784) \\\n",
        "                        .reshape(length, 28, 28, 1)\n",
        "        \n",
        "    return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swOquxKonP6m"
      },
      "source": [
        "train = {}\n",
        "test = {}\n",
        "\n",
        "train['features'], train['labels'] = read_mnist('train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCVa2LgMnZTe"
      },
      "source": [
        "test['features'], test['labels'] = read_mnist('t10k-images-idx3-ubyte1.gz', 't10k-labels-idx1-ubyte1.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CF4YHFM3GXN"
      },
      "source": [
        "**Exploring the Data after loading it into training and testing data frame variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBYBBwHYo91D"
      },
      "source": [
        "print('# of training images:', train['features'].shape[0])\n",
        "print('# of test images:', test['features'].shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hPamafTqFqU"
      },
      "source": [
        "def display_image(position):\n",
        "    image = train['features'][position].squeeze()\n",
        "    plt.title('Example %d. Label: %d' % (position, train['labels'][position]))\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIZeHEc23ag8"
      },
      "source": [
        "# Viewing few of the items from the data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R73xxuzLqKo1"
      },
      "source": [
        "display_image(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvqMOSIQqTM1"
      },
      "source": [
        "display_image(9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSCm7BdbqUtz"
      },
      "source": [
        "display_image(1998)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02Jw2Bq0qWh6"
      },
      "source": [
        "display_image(15998)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBaKIe2EqdJx"
      },
      "source": [
        "#this dataset has labelled from 0-9 \n",
        "train_labels_count = np.unique(train['labels'], return_counts=True)\n",
        "dataframe_train_labels = pd.DataFrame({'Label':train_labels_count[0], 'Count':train_labels_count[1]})\n",
        "dataframe_train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJB1YCIiqn6i"
      },
      "source": [
        "#spliting the data into 80% for training and remaining 20% is for testing\n",
        "validation = {}\n",
        "train['features'], validation['features'], train['labels'], validation['labels'] = train_test_split(train['features'], train['labels'], test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ekv5Lb3U4R6W"
      },
      "source": [
        "# Number of instances in training and testing data variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLAjaHE3qq3s"
      },
      "source": [
        "print('# of training images:', train['features'].shape[0])\n",
        "print('# of validation images:', validation['features'].shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWkR1j2GqtYG"
      },
      "source": [
        "# Pad images with 0s\n",
        "train['features']      = np.pad(train['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "validation['features'] = np.pad(validation['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "test['features']       = np.pad(test['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "    \n",
        "print(\"Updated Image Shape: {}\".format(train['features'][0].shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6E0OigR4q8G"
      },
      "source": [
        "#### Input\n",
        "    32x32x1 pixels image\n",
        "\n",
        "#### Architecture\n",
        "* **Convolutional #1** outputs 28x28x6\n",
        "    * **Activation** any activation function, we will `relu`\n",
        "\n",
        "* **Pooling #1** The output shape should be 14x14x6.\n",
        "\n",
        "* **Convolutional #2** outputs 10x10x16.\n",
        "    * **Activation** any activation function, we will `relu`\n",
        "\n",
        "* **Pooling #2** outputs 5x5x16.\n",
        "    * **Flatten** Flatten the output shape of the final pooling layer\n",
        "\n",
        "* **Fully Connected #1** outputs 120\n",
        "    * **Activation** any activation function, we will `relu`\n",
        "\n",
        "* **Fully Connected #2** outputs 84\n",
        "    * **Activation** any activation function, we will `relu`\n",
        "\n",
        "* **Fully Connected (Logits) #3** outpute 10\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhlkDK0iqwsE"
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=10, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoOHW_a-vAtP"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aW2Uxr7wHz_"
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f91veIDTwLuN"
      },
      "source": [
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCMHQ6XMwOP1"
      },
      "source": [
        "X_train, y_train = train['features'], to_categorical(train['labels'])\n",
        "X_validation, y_validation = validation['features'], to_categorical(validation['labels'])\n",
        "\n",
        "train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
        "validation_generator = ImageDataGenerator().flow(X_validation, y_validation, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVNyIQ72wRMv"
      },
      "source": [
        "print('# of training images:', train['features'].shape[0])\n",
        "print('# of validation images:', validation['features'].shape[0])\n",
        "\n",
        "steps_per_epoch = X_train.shape[0]//BATCH_SIZE\n",
        "validation_steps = X_validation.shape[0]//BATCH_SIZE\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
        "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \n",
        "                    validation_data=validation_generator, validation_steps=validation_steps, \n",
        "                    shuffle=True, callbacks=[tensorboard])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8FmzHDawTk2"
      },
      "source": [
        "score = model.evaluate(test['features'], to_categorical(test['labels']))\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exbzsFbXxFgV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}